[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\nNow this works!!!!\n\nx= 1+5\nx\n\n[1] 6\n\n\n\nLoad Libraries\nlibrary(readxl) library(caret) library(rpart) library(caretEnsemble) library(tidyverse) library(fastshap) library(readr) library(data.table) library(mltools) library(MLmetrics) library(conflicted) library(parallel) library(doParallel) conflicts_prefer(dplyr::filter)\n\n\nCheck out individual models\nget_best_result = function(caret_fit) { best = which(rownames(caret_fit\\(results) == rownames(caret_fit\\)bestTune)) best_result = caret_fit$results[best, ] rownames(best_result) = NULL best_result }\n\n\nset WD and load data\nlibrary(here) ProjectData &lt;- read_excel(“DataScience_Data.xlsx”) names(ProjectData) summary(ProjectData)\nhist(ProjectData$BAARS) #39+ for diagnosis\n#Sample Size ProjectData %&gt;% summarise(n = n())\n\n\n#Question 1: What factors best predict the ADHD diagnosis? ########################################################################################\n#Variables to keep ProjectData.K&lt;-ProjectData %&gt;% select(Participant, L2, SRT, DM, WM, BAARS, ADHD, PHQ, Sex, Age, SpokenLanguages, Education) summary(ProjectData.K)\nProjectData.K\\(Participant &lt;- as.factor(ProjectData.K\\)Participant)\nProjectData.K\\(ADHD[ProjectData.K\\)ADHD == 1] &lt;- “adhd” ProjectData.K\\(ADHD[ProjectData.K\\)ADHD == 0] &lt;- “no_adhd” ProjectData.K\\(ADHD &lt;- as.factor(ProjectData.K\\)ADHD)\ntable(ProjectData.K$ADHD) ## Split\nset.seed(666) # For reproducibility\n\n\n\n75% of data will go into training\ntrain_idx &lt;- createDataPartition(ProjectData.K$ADHD, p = 0.75, list = FALSE)\n\n\nCreate training and test datasets\ntrain_data_ADHD_Status &lt;- ProjectData.K[train_idx, ] test_data_ADHD_Status &lt;- ProjectData.K[-train_idx, ]\ntable(train_data_ADHD_Status\\(ADHD)\ntable(test_data_ADHD_Status\\)ADHD) prop.table(table(train_data_ADHD_Status\\(ADHD))\nprop.table(table(test_data_ADHD_Status\\)ADHD))\n\n\n#########Set up all models ################################### ############################################################## # Set up cross-validation using ROC as the metric BI_cv_control &lt;- trainControl( method = “cv”, #trained on 9, validated on 1 number = 10, #split data into 10 folds # summaryFunction = prSummary, # Use caret’s prSummary for binary classification for AUC # summaryFunction = twoClassSummary, # Use caret’s twoClassSummary for binary classification for ROC metric # summaryFunction = defaultSummary, # Use caret’s defaultSummary for binary classification for accuracy summaryFunction = multiClassSummary, # multiClassSummary returns Mean_Balanced_Accuracy classProbs = TRUE, allowParallel = TRUE, savePredictions = “final” )\n\n\n\nSetup parallel processing\ncl &lt;- makePSOCKcluster(detectCores()) registerDoParallel(cl)\n\n\nTrain binary models for group 0 (using base predictors)\nmodels.binary_ADHD_1 &lt;- caretList( ADHD ~ SRT+DM+WM+PHQ+Sex+Age+Education, data = train_data_ADHD_Status, trControl = BI_cv_control, #metric = “AUC”, metric = “Mean_Balanced_Accuracy”, tuneList = list( # Logistic regression for binary classification Logit = caretModelSpec( method = “glm”, preProcess = c(“center”, “scale”), family = “binomial” ), # Lasso using glmnet with family binomial Lasso = caretModelSpec( method = “glmnet”, preProcess = c(“center”, “scale”), tuneGrid = expand.grid(alpha = 1, lambda = seq(0.005, 0.1, 0.005)), family = “binomial” ), # Linear Discriminant Analysis LDA = caretModelSpec( method = “lda”, preProcess = c(“center”, “scale”) ), # Quadratic Discriminant Analysis QDA = caretModelSpec( method = “qda”, preProcess = c(“center”, “scale”) ), # Random Forest model RF = caretModelSpec( method = “rf”, preProcess = c(“center”, “scale”), tuneGrid = expand.grid(mtry = seq(1, 10, 1)), ntree = 1000, importance = TRUE ), # XGBoost model for classification XGBOOST = caretModelSpec( method = “xgbTree”, preProcess = c(“center”, “scale”), verbosity = 0, tuneGrid = expand.grid( nrounds = 20, max_depth = 3, eta = 0.3, gamma = seq(0.1, 0.3, 0.05), colsample_bytree = 1, min_child_weight = 1, subsample = seq(0.7, 0.8, 0.05) ) ) ) )\n\n\nTrain binary models for group 1 (adding language info)\nmodels.binary_ADHD_2 &lt;- caretList( ADHD ~ SRT+DM+WM+PHQ+Sex+Age+Education+L2+SpokenLanguages, data = train_data_ADHD_Status, trControl = BI_cv_control, #metric = “AUC”, metric = “Mean_Balanced_Accuracy”, tuneList = list( # Logistic regression for binary classification Logit = caretModelSpec( method = “glm”, preProcess = c(“center”, “scale”), family = “binomial” ), # Lasso using glmnet with family binomial Lasso = caretModelSpec( method = “glmnet”, preProcess = c(“center”, “scale”), tuneGrid = expand.grid(alpha = 1, lambda = seq(0.005, 0.1, 0.005)), family = “binomial” ), # Linear Discriminant Analysis LDA = caretModelSpec( method = “lda”, preProcess = c(“center”, “scale”) ), # Quadratic Discriminant Analysis QDA = caretModelSpec( method = “qda”, preProcess = c(“center”, “scale”) ), # Random Forest model RF = caretModelSpec( method = “rf”, preProcess = c(“center”, “scale”), tuneGrid = expand.grid(mtry = seq(1, 10, 1)), ntree = 1000, importance = TRUE ), # XGBoost model for classification XGBOOST = caretModelSpec( method = “xgbTree”, preProcess = c(“center”, “scale”), verbosity = 0, tuneGrid = expand.grid( nrounds = 20, max_depth = 3, eta = 0.3, gamma = seq(0.1, 0.3, 0.05), colsample_bytree = 1, min_child_weight = 1, subsample = seq(0.7, 0.8, 0.05) ) ) ) )\n\n\nTrain binary models for group 2 (adding BAARS survey)\nmodels.binary_ADHD_3 &lt;- caretList( ADHD ~ SRT+DM+WM+PHQ+Sex+Age+Education+L2+SpokenLanguages+BAARS, data = train_data_ADHD_Status, trControl = BI_cv_control, #metric = “AUC”, metric = “Mean_Balanced_Accuracy”, tuneList = list( # Logistic regression for binary classification Logit = caretModelSpec( method = “glm”, preProcess = c(“center”, “scale”), family = “binomial” ), # Lasso using glmnet with family binomial Lasso = caretModelSpec( method = “glmnet”, preProcess = c(“center”, “scale”), tuneGrid = expand.grid(alpha = 1, lambda = seq(0.005, 0.1, 0.005)), family = “binomial” ), # Linear Discriminant Analysis LDA = caretModelSpec( method = “lda”, preProcess = c(“center”, “scale”) ), # Quadratic Discriminant Analysis QDA = caretModelSpec( method = “qda”, preProcess = c(“center”, “scale”) ), # Random Forest model RF = caretModelSpec( method = “rf”, preProcess = c(“center”, “scale”), tuneGrid = expand.grid(mtry = seq(1, 10, 1)), ntree = 1000, importance = TRUE ), # XGBoost model for classification XGBOOST = caretModelSpec( method = “xgbTree”, preProcess = c(“center”, “scale”), verbosity = 0, tuneGrid = expand.grid( nrounds = 20, max_depth = 3, eta = 0.3, gamma = seq(0.1, 0.3, 0.05), colsample_bytree = 1, min_child_weight = 1, subsample = seq(0.7, 0.8, 0.05) ) ) ) )\n\n\nStop parallel processing when finished\nstopCluster(cl)\n\n\nCompare resampling results across all binary models\nresults.binary.ADHD_1 &lt;- resamples(models.binary_ADHD_1) results.binary.ADHD_2 &lt;- resamples(models.binary_ADHD_2) results.binary.ADHD_3 &lt;- resamples(models.binary_ADHD_3) bwplot(results.binary.ADHD_1, scales = list(x = list(relation = “free”), y = list(relation = “free”))) bwplot(results.binary.ADHD_2, scales = list(x = list(relation = “free”), y = list(relation = “free”))) bwplot(results.binary.ADHD_3, scales = list(x = list(relation = “free”), y = list(relation = “free”)))\n\n\nHelper function to extract confusion matrices for a given model list\nextract_CM &lt;- function(model_list, train_data, test_data, response_col) { # Loop over models in the list and compute confusion matrices cm_train &lt;- lapply(model_list, function(mod) { confusionMatrix( predict(mod, newdata = train_data), reference = train_data[[response_col]] ) })\ncm_test &lt;- lapply(model_list, function(mod) { confusionMatrix( predict(mod, newdata = test_data), reference = test_data[[response_col]] ) })\n# Return a list containing both training and testing confusion matrices list(Train = cm_train, Test = cm_test) }\n\n\nExtract confusion matrices for each group\nCM.models.binary_ADHD_1 &lt;- extract_CM(models.binary_ADHD_1, train_data_ADHD_Status, test_data_ADHD_Status, “ADHD”) CM.models.binary_ADHD_2 &lt;- extract_CM(models.binary_ADHD_2, train_data_ADHD_Status, test_data_ADHD_Status, “ADHD”) CM.models.binary_ADHD_3 &lt;- extract_CM(models.binary_ADHD_3, train_data_ADHD_Status, test_data_ADHD_Status, “ADHD”)\n\n\nOptionally, print all confusion matrices for each group and each model\nprint_confusion_matrices &lt;- function(cm_list, group_name) { cat(“— Confusion Matrices for”, group_name, “—”) for(model_name in names(cm_list\\(Train)) {\n    cat(\"\\nModel:\", model_name, \"\\n\")\n    cat(\"Training Data:\\n\")\n    print(cm_list\\)Train[[model_name]]) cat(“Data:”) print(cm_list$Test[[model_name]]) cat(“——————————-”) } }\n\n\nPrint confusion matrices for each group\nprint_confusion_matrices(CM.models.binary_ADHD_1, “models.binary_ADHD_1”) print_confusion_matrices(CM.models.binary_ADHD_2, “models.binary_ADHD_2”) print_confusion_matrices(CM.models.binary_ADHD_3, “models.binary_ADHD_3”)\n#confusion matrix for RF only #CM.models.binary_ADHD_3\\(Train\\)RF #CM.models.binary_ADHD_3\\(Test\\)RF\n#RF seems the winner (I do not think that Alex agreed here). # Updated helper function to compute Mean_Balanced_Accuracy using multiClassSummary calc_balacc &lt;- function(mod, truth, newdata) { # Get predicted probabilities and predicted class labels prob &lt;- predict(mod, newdata = newdata, type = “prob”) pred &lt;- predict(mod, newdata = newdata)\n# Build a data frame with observed values, predictions, and probabilities. # The column names in ‘prob’ must match the levels in the response factor. df &lt;- data.frame(obs = truth, pred = pred, prob)\n# multiClassSummary computes several metrics including Mean_Balanced_Accuracy. # Note: Even in binary classification, it returns “Mean_Balanced_Accuracy”. metrics &lt;- multiClassSummary(df, lev = levels(truth), model = mod) metrics[“Balanced_Accuracy”] }\n\n\nUpdated evaluation function that computes balanced accuracy on train and test sets\nevaluate_models_balacc &lt;- function(model_list, train_data, test_data, response_col) { train_balacc &lt;- sapply(model_list, function(mod) calc_balacc(mod, truth = train_data[[response_col]], newdata = train_data))\ntest_balacc &lt;- sapply(model_list, function(mod) calc_balacc(mod, truth = test_data[[response_col]], newdata = test_data))\ndata.frame( Model = names(model_list), Train_BalAcc = train_balacc, Test_BalAcc = test_balacc, Diff = train_balacc - test_balacc, row.names = NULL ) }\n\n\nExample usage for group 1 and group 2 binary models\nBI_results1 &lt;- evaluate_models_balacc( model_list = models.binary_ADHD_1, train_data = train_data_ADHD_Status, test_data = test_data_ADHD_Status, response_col = “ADHD” )\nBI_results2 &lt;- evaluate_models_balacc( model_list = models.binary_ADHD_2, train_data = train_data_ADHD_Status, test_data = test_data_ADHD_Status, response_col = “ADHD” )\nBI_results3 &lt;- evaluate_models_balacc( model_list = models.binary_ADHD_3, train_data = train_data_ADHD_Status, test_data = test_data_ADHD_Status, response_col = “ADHD” )\n\n\nCombine the results from the two groups for comparison\nBI_results1\\(Set &lt;- \"No L2\"\nBI_results2\\)Set &lt;- “With L2” BI_results3$Set &lt;- “BAARS” BI_results_all &lt;- rbind(BI_results1, BI_results2, BI_results3)\n\n\nPrint the combined balanced accuracy results\nBI_results_all\n\nSHAP Values for RF\n\n\n\nCreate a character vector with the names of your selected predictors\nselected_vars &lt;- c(“L2”, “SRT”, “DM”, “WM”, “PHQ”, “Sex”, “Age”, “SpokenLanguages”, “Education”, “BAARS”)\n\n\nSubset the training data for SHAP analysis\nBI_X_train &lt;- ProjectData[, selected_vars]\n\n\nFor binary classification, define a prediction wrapper that returns probabilities for the positive class.\npredict_prob_BI &lt;- function(model, newdata) { prob &lt;- predict(model, newdata = newdata, type = “prob”) prob[, 2] }\n\n\nCompute SHAP values using fastshap for one of the QDR models\nset.seed(123) # For reproducibility\nBI_shap_vals_RF &lt;- fastshap::explain( object = models.binary_ADHD_2$RF, X = BI_X_train, pred_wrapper = predict_prob_BI, nsim = 50 )\n\n\nCalculate Signed and Absolute Mean SHAP values for each predictor\nBI_signed_mean_RF &lt;- colMeans(BI_shap_vals_RF) BI_abs_mean_RF &lt;- colMeans(abs(BI_shap_vals_RF))\n\n\nCombine the SHAP means into a data frame for plotting.\ndf_BI_shap_means &lt;- data.frame( Variable = names(BI_signed_mean_RF), Signed = BI_signed_mean_RF, Absolute = BI_abs_mean_RF )\n\n\nConvert to long format for ggplot.\ndf_BI_shap_long &lt;- df_BI_shap_means %&gt;% pivot_longer(cols = c(Signed, Absolute), names_to = “Metric”, values_to = “Mean_SHAP”)\n\n\nCreate a bar plot of the mean SHAP values.\nShap_Means_BI &lt;- ggplot(df_BI_shap_long, aes(x = Variable, y = Mean_SHAP, fill = Metric)) + facet_wrap(~ Metric, scales = “free”) + geom_bar(stat = “identity”, position = “dodge”) + labs(title = “Mean SHAP Values for RF Binary Model”, x = “Variable”, y = “Mean SHAP Value”) + coord_flip() + theme_minimal()\nShap_Means_BI"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "portfolio",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  }
]