[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "ADHD Diagnosis Predictor",
    "section": "",
    "text": "This project aims to answer the following research question: What factors best predict the ADHD diagnosis?\n#Step 1: Loadings libraries and preparing data sets\nLoad Libraries\n\nlibrary(readxl)\nlibrary(caret)\nlibrary(rpart)\nlibrary(caretEnsemble)\nlibrary(tidyverse)\nlibrary(fastshap)\nlibrary(readr)\nlibrary(data.table)\nlibrary(mltools)\nlibrary(MLmetrics)\nlibrary(conflicted)\nlibrary(parallel)\nlibrary(doParallel)\nlibrary(here)\n\nconflicts_prefer(dplyr::filter)\n\nSet WD, load data, and check the names of the variables from the data set\n\nProjectData &lt;- read_excel(\"DataScience_Data.xlsx\")\nnames(ProjectData)\n\n [1] \"Participant\"     \"Complex\"         \"Simple\"          \"L2\"             \n [5] \"SRT\"             \"Declearn\"        \"MLAT\"            \"DM\"             \n [9] \"Ospan\"           \"Rspan\"           \"Sspan\"           \"WM\"             \n[13] \"BAARS\"           \"ADHD\"            \"PHQ\"             \"Sex\"            \n[17] \"Age\"             \"SpokenLanguages\" \"Education\"      \n\nsummary(ProjectData)\n\n  Participant      Complex           Simple             L2        \n Min.   :4201   Min.   :0.0000   Min.   :0.1700   Min.   :0.2200  \n 1st Qu.:4317   1st Qu.:0.1700   1st Qu.:0.5800   1st Qu.:0.5000  \n Median :4401   Median :0.3300   Median :0.7500   Median :0.6100  \n Mean   :4407   Mean   :0.3552   Mean   :0.7141   Mean   :0.5948  \n 3rd Qu.:4503   3rd Qu.:0.5000   3rd Qu.:0.9200   3rd Qu.:0.6700  \n Max.   :4603   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                  \n      SRT             Declearn           MLAT             DM           \n Min.   :-0.2000   Min.   :-0.140   Min.   : 2.00   Min.   :-2.489000  \n 1st Qu.: 0.0400   1st Qu.: 1.040   1st Qu.:13.00   1st Qu.:-0.481000  \n Median : 0.0900   Median : 1.400   Median :17.00   Median : 0.089000  \n Mean   : 0.0851   Mean   : 1.307   Mean   :16.61   Mean   :-0.001092  \n 3rd Qu.: 0.1300   3rd Qu.: 1.680   3rd Qu.:20.00   3rd Qu.: 0.519000  \n Max.   : 0.3700   Max.   : 2.850   Max.   :24.00   Max.   : 1.485000  \n                                                                       \n     Ospan           Rspan           Sspan             WM       \n Min.   : 3.00   Min.   : 1.00   Min.   : 0.00   Min.   :15.00  \n 1st Qu.:19.00   1st Qu.:19.00   1st Qu.:12.00   1st Qu.:55.00  \n Median :24.00   Median :23.00   Median :16.00   Median :64.00  \n Mean   :22.33   Mean   :21.65   Mean   :14.88   Mean   :61.97  \n 3rd Qu.:28.00   3rd Qu.:27.00   3rd Qu.:19.00   3rd Qu.:72.00  \n Max.   :30.00   Max.   :30.00   Max.   :24.00   Max.   :84.00  \n NA's   :1                                                      \n     BAARS            ADHD             PHQ              Sex        \n Min.   :18.00   Min.   :0.0000   Min.   : 0.000   Min.   :0.0000  \n 1st Qu.:29.00   1st Qu.:0.0000   1st Qu.: 6.000   1st Qu.:0.0000  \n Median :35.00   Median :0.0000   Median : 9.000   Median :1.0000  \n Mean   :36.75   Mean   :0.2876   Mean   : 9.778   Mean   :0.6993  \n 3rd Qu.:45.00   3rd Qu.:1.0000   3rd Qu.:14.000   3rd Qu.:1.0000  \n Max.   :68.00   Max.   :1.0000   Max.   :27.000   Max.   :2.0000  \n                                                                   \n      Age        SpokenLanguages   Education    \n Min.   :18.00   Min.   :1.000   Min.   :12.00  \n 1st Qu.:18.00   1st Qu.:2.000   1st Qu.:13.00  \n Median :19.00   Median :2.000   Median :13.50  \n Mean   :20.08   Mean   :2.327   Mean   :14.25  \n 3rd Qu.:20.00   3rd Qu.:3.000   3rd Qu.:15.00  \n Max.   :38.00   Max.   :5.000   Max.   :19.00  \n                                                \n\nhist(ProjectData$BAARS)\n\n\n\n\n\n\n\n#39+ for diagnosis\n\n\n#Sample Size\nProjectData %&gt;% summarise(n = n())\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1   153\n\n\nVariables to keep\n\nProjectData.K&lt;-ProjectData %&gt;% \n  select(Participant, L2, SRT, DM, WM, BAARS, ADHD, PHQ, \n         Sex, Age, SpokenLanguages, Education)\nsummary(ProjectData.K)\n\n  Participant         L2              SRT                DM           \n Min.   :4201   Min.   :0.2200   Min.   :-0.2000   Min.   :-2.489000  \n 1st Qu.:4317   1st Qu.:0.5000   1st Qu.: 0.0400   1st Qu.:-0.481000  \n Median :4401   Median :0.6100   Median : 0.0900   Median : 0.089000  \n Mean   :4407   Mean   :0.5948   Mean   : 0.0851   Mean   :-0.001092  \n 3rd Qu.:4503   3rd Qu.:0.6700   3rd Qu.: 0.1300   3rd Qu.: 0.519000  \n Max.   :4603   Max.   :1.0000   Max.   : 0.3700   Max.   : 1.485000  \n       WM            BAARS            ADHD             PHQ        \n Min.   :15.00   Min.   :18.00   Min.   :0.0000   Min.   : 0.000  \n 1st Qu.:55.00   1st Qu.:29.00   1st Qu.:0.0000   1st Qu.: 6.000  \n Median :64.00   Median :35.00   Median :0.0000   Median : 9.000  \n Mean   :61.97   Mean   :36.75   Mean   :0.2876   Mean   : 9.778  \n 3rd Qu.:72.00   3rd Qu.:45.00   3rd Qu.:1.0000   3rd Qu.:14.000  \n Max.   :84.00   Max.   :68.00   Max.   :1.0000   Max.   :27.000  \n      Sex              Age        SpokenLanguages   Education    \n Min.   :0.0000   Min.   :18.00   Min.   :1.000   Min.   :12.00  \n 1st Qu.:0.0000   1st Qu.:18.00   1st Qu.:2.000   1st Qu.:13.00  \n Median :1.0000   Median :19.00   Median :2.000   Median :13.50  \n Mean   :0.6993   Mean   :20.08   Mean   :2.327   Mean   :14.25  \n 3rd Qu.:1.0000   3rd Qu.:20.00   3rd Qu.:3.000   3rd Qu.:15.00  \n Max.   :2.0000   Max.   :38.00   Max.   :5.000   Max.   :19.00  \n\nProjectData.K$Participant &lt;- as.factor(ProjectData.K$Participant)\n\nProjectData.K$ADHD[ProjectData.K$ADHD == 1] &lt;- \"adhd\"\nProjectData.K$ADHD[ProjectData.K$ADHD == 0] &lt;- \"no_adhd\"\nProjectData.K$ADHD &lt;- as.factor(ProjectData.K$ADHD)\n\ntable(ProjectData.K$ADHD)\n\n\n   adhd no_adhd \n     44     109 \n\n\nSplit the data and create training and testing data sets 75% of data will go into the training and 25% of data will go into the testing sets\n\nset.seed(666)  # Set seed, so that the model produce the consistent results for reproducibility\n\ntrain_idx &lt;- createDataPartition(ProjectData.K$ADHD, p = 0.75, list = FALSE)\n\n# Create training and test datasets\ntrain_data_ADHD_Status &lt;- ProjectData.K[train_idx, ]\ntest_data_ADHD_Status  &lt;- ProjectData.K[-train_idx, ]\n\ntable(train_data_ADHD_Status$ADHD)\n\n\n   adhd no_adhd \n     33      82 \n\ntable(test_data_ADHD_Status$ADHD)\n\n\n   adhd no_adhd \n     11      27 \n\nprop.table(table(train_data_ADHD_Status$ADHD))\n\n\n     adhd   no_adhd \n0.2869565 0.7130435 \n\nprop.table(table(test_data_ADHD_Status$ADHD))\n\n\n     adhd   no_adhd \n0.2894737 0.7105263 \n\n\n#Step 2: Set up all models\n\n# Set up cross-validation using ROC as the metric\nBI_cv_control &lt;- trainControl(\n  method = \"cv\", #trained on 9, validated on 1\n  number = 10, #split data into 10 folds\n  # summaryFunction = prSummary,   # Use caret’s prSummary for binary classification for AUC\n  # summaryFunction = twoClassSummary,   # Use caret’s twoClassSummary for binary classification for ROC metric\n  # summaryFunction = defaultSummary,   # Use caret’s defaultSummary for binary classification for accuracy\n  summaryFunction = multiClassSummary,   # multiClassSummary returns Mean_Balanced_Accuracy\n  classProbs = TRUE,\n  allowParallel = TRUE,\n  savePredictions = \"final\"\n)\n\n# Setup parallel processing\ncl &lt;- makePSOCKcluster(detectCores())\nregisterDoParallel(cl)\n\nTrain models to see which fits the data better The first set of models includes only control variables: memory learning scores, age, sex, and education\n\nmodels.binary_ADHD_1 &lt;- caretList(\n  ADHD ~ SRT+DM+WM+PHQ+Sex+Age+Education,\n  data = train_data_ADHD_Status,\n  trControl = BI_cv_control,\n  #metric = \"AUC\",\n  metric = \"Mean_Balanced_Accuracy\",\n  tuneList = list(\n    # Logistic regression for binary classification\n    Logit = caretModelSpec(\n      method = \"glm\",\n      preProcess = c(\"center\", \"scale\"),\n      family = \"binomial\"\n    ),\n    # Lasso using glmnet with family binomial\n    Lasso = caretModelSpec(\n      method = \"glmnet\",\n      preProcess = c(\"center\", \"scale\"),\n      tuneGrid = expand.grid(alpha = 1, lambda = seq(0.005, 0.1, 0.005)),\n      family = \"binomial\"\n    ),\n    # Linear Discriminant Analysis\n    LDA = caretModelSpec(\n      method = \"lda\",\n      preProcess = c(\"center\", \"scale\")\n    ),\n    # Quadratic Discriminant Analysis\n    QDA = caretModelSpec(\n      method = \"qda\",\n      preProcess = c(\"center\", \"scale\")\n    ),\n    # Random Forest model\n    RF = caretModelSpec(\n      method = \"rf\",\n      preProcess = c(\"center\", \"scale\"),\n      tuneGrid = expand.grid(mtry = seq(1, 10, 1)),\n      ntree = 1000,\n      importance = TRUE\n    ),\n    # XGBoost model for classification\n    XGBOOST = caretModelSpec(\n      method = \"xgbTree\",\n      preProcess = c(\"center\", \"scale\"),\n      verbosity = 0,\n      tuneGrid = expand.grid(\n        nrounds = 20,\n        max_depth = 3, \n        eta = 0.3,\n        gamma = seq(0.1, 0.3, 0.05),\n        colsample_bytree = 1,\n        min_child_weight = 1,\n        subsample = seq(0.7, 0.8, 0.05)\n      )\n    )\n  )\n)\n\nTrain binary models for group 1 (adding language info)\n\nmodels.binary_ADHD_2 &lt;- caretList(\n  ADHD ~ SRT+DM+WM+PHQ+Sex+Age+Education+L2+SpokenLanguages,\n  data = train_data_ADHD_Status,\n  trControl = BI_cv_control,\n  #metric = \"AUC\",\n  metric = \"Mean_Balanced_Accuracy\",\n  tuneList = list(\n    # Logistic regression for binary classification\n    Logit = caretModelSpec(\n      method = \"glm\",\n      preProcess = c(\"center\", \"scale\"),\n      family = \"binomial\"\n    ),\n    # Lasso using glmnet with family binomial\n    Lasso = caretModelSpec(\n      method = \"glmnet\",\n      preProcess = c(\"center\", \"scale\"),\n      tuneGrid = expand.grid(alpha = 1, lambda = seq(0.005, 0.1, 0.005)),\n      family = \"binomial\"\n    ),\n    # Linear Discriminant Analysis\n    LDA = caretModelSpec(\n      method = \"lda\",\n      preProcess = c(\"center\", \"scale\")\n    ),\n    # Quadratic Discriminant Analysis\n    QDA = caretModelSpec(\n      method = \"qda\",\n      preProcess = c(\"center\", \"scale\")\n    ),\n    # Random Forest model\n    RF = caretModelSpec(\n      method = \"rf\",\n      preProcess = c(\"center\", \"scale\"),\n      tuneGrid = expand.grid(mtry = seq(1, 10, 1)),\n      ntree = 1000,\n      importance = TRUE\n    ),\n    # XGBoost model for classification\n    XGBOOST = caretModelSpec(\n      method = \"xgbTree\",\n      preProcess = c(\"center\", \"scale\"),\n      verbosity = 0,\n      tuneGrid = expand.grid(\n        nrounds = 20,\n        max_depth = 3, \n        eta = 0.3,\n        gamma = seq(0.1, 0.3, 0.05),\n        colsample_bytree = 1,\n        min_child_weight = 1,\n        subsample = seq(0.7, 0.8, 0.05)\n      )\n    )\n  )\n)\n\nTrain binary models for group 3 (adding BAARS survey)\n\nmodels.binary_ADHD_3 &lt;- caretList(\n  ADHD ~ SRT+DM+WM+PHQ+Sex+Age+Education+L2+SpokenLanguages+BAARS,\n  data = train_data_ADHD_Status,\n  trControl = BI_cv_control,\n  #metric = \"AUC\",\n  metric = \"Mean_Balanced_Accuracy\",\n  tuneList = list(\n    # Logistic regression for binary classification\n    Logit = caretModelSpec(\n      method = \"glm\",\n      preProcess = c(\"center\", \"scale\"),\n      family = \"binomial\"\n    ),\n    # Lasso using glmnet with family binomial\n    Lasso = caretModelSpec(\n      method = \"glmnet\",\n      preProcess = c(\"center\", \"scale\"),\n      tuneGrid = expand.grid(alpha = 1, lambda = seq(0.005, 0.1, 0.005)),\n      family = \"binomial\"\n    ),\n    # Linear Discriminant Analysis\n    LDA = caretModelSpec(\n      method = \"lda\",\n      preProcess = c(\"center\", \"scale\")\n    ),\n    # Quadratic Discriminant Analysis\n    QDA = caretModelSpec(\n      method = \"qda\",\n      preProcess = c(\"center\", \"scale\")\n    ),\n    # Random Forest model\n    RF = caretModelSpec(\n      method = \"rf\",\n      preProcess = c(\"center\", \"scale\"),\n      tuneGrid = expand.grid(mtry = seq(1, 10, 1)),\n      ntree = 1000,\n      importance = TRUE\n    ),\n    # XGBoost model for classification\n    XGBOOST = caretModelSpec(\n      method = \"xgbTree\",\n      preProcess = c(\"center\", \"scale\"),\n      verbosity = 0,\n      tuneGrid = expand.grid(\n        nrounds = 20,\n        max_depth = 3, \n        eta = 0.3,\n        gamma = seq(0.1, 0.3, 0.05),\n        colsample_bytree = 1,\n        min_child_weight = 1,\n        subsample = seq(0.7, 0.8, 0.05)\n      )\n    )\n  )\n)\n\n\n# Stop parallel processing when finished\nstopCluster(cl)\n\nStep 3: Resampling results from all models and creating the metrics\n\n# Compare resampling results across all binary models\nresults.binary.ADHD_1 &lt;- resamples(models.binary_ADHD_1)\nbwplot(results.binary.ADHD_1, metric = c(\"Sensitivity\", \"Specificity\", \"Balanced_Accuracy\", \"Accuracy\"),  \n       scales = list(x = list(relation = \"free\"), y = list(relation = \"free\")))\n\n\n\n\n\n\n\nresults.binary.ADHD_2 &lt;- resamples(models.binary_ADHD_2)\nbwplot(results.binary.ADHD_2, metric = c(\"Sensitivity\", \"Specificity\", \"Balanced_Accuracy\", \"Accuracy\"),  \n       scales = list(x = list(relation = \"free\"), y = list(relation = \"free\")))\n\n\n\n\n\n\n\nresults.binary.ADHD_3 &lt;- resamples(models.binary_ADHD_3)\nbwplot(results.binary.ADHD_3, metric = c(\"Sensitivity\", \"Specificity\", \"Balanced_Accuracy\", \"Accuracy\"),  \n       scales = list(x = list(relation = \"free\"), y = list(relation = \"free\")))\n\n\n\n\n\n\n\n\n\n# Helper function to extract confusion matrices for a given model list\nextract_CM &lt;- function(model_list, train_data, test_data, response_col) {\n  # Loop over models in the list and compute confusion matrices\n  cm_train &lt;- lapply(model_list, function(mod) {\n    confusionMatrix(\n      predict(mod, newdata = train_data),\n      reference = train_data[[response_col]]\n    )\n  })\n  \n  cm_test &lt;- lapply(model_list, function(mod) {\n    confusionMatrix(\n      predict(mod, newdata = test_data),\n      reference = test_data[[response_col]]\n    )\n  })\n  \n  # Return a list containing both training and testing confusion matrices\n  list(Train = cm_train, Test = cm_test)\n}\n\n# Extract confusion matrices for each group\nCM.models.binary_ADHD_1 &lt;- extract_CM(models.binary_ADHD_1, train_data_ADHD_Status, test_data_ADHD_Status, \"ADHD\")\nCM.models.binary_ADHD_2 &lt;- extract_CM(models.binary_ADHD_2, train_data_ADHD_Status, test_data_ADHD_Status, \"ADHD\")\nCM.models.binary_ADHD_3 &lt;- extract_CM(models.binary_ADHD_3, train_data_ADHD_Status, test_data_ADHD_Status, \"ADHD\")\n\n# Optionally, print all confusion matrices for each group and each model\n#print_confusion_matrices &lt;- function(cm_list, group_name) {\n#  cat(\"\\n--- Confusion Matrices for\", group_name, \"---\\n\")\n#  for(model_name in names(cm_list$Train)) {\n#    cat(\"\\nModel:\", model_name, \"\\n\")\n#    cat(\"Training Data:\\n\")\n#    print(cm_list$Train[[model_name]])\n#    cat(\"\\nTesting Data:\\n\")\n#    print(cm_list$Test[[model_name]])\n#    cat(\"\\n-------------------------------\\n\")\n#  }\n#}\n\n# Print confusion matrices for each group\n#print_confusion_matrices(CM.models.binary_ADHD_1, \"models.binary_ADHD_1\")\n#print_confusion_matrices(CM.models.binary_ADHD_2, \"models.binary_ADHD_2\")\n#print_confusion_matrices(CM.models.binary_ADHD_3, \"models.binary_ADHD_3\")\n\n#confusion matrix for XGBOOST only\n#CM.models.binary_ADHD_1$Train$XGBOOST\n#CM.models.binary_ADHD_1$Test$XGBOOST\n\n#CM.models.binary_ADHD_2$Train$XGBOOST\n#CM.models.binary_ADHD_2$Test$XGBOOST\n\n#CM.models.binary_ADHD_3$Train$XGBOOST\n#CM.models.binary_ADHD_3$Test$XGBOOST\n\n##############\nextract_metrics &lt;- function(cm_obj) {\n  data.frame(\n    Accuracy = cm_obj$overall[\"Accuracy\"],\n    Sensitivity = cm_obj$byClass[\"Sensitivity\"],\n    Specificity = cm_obj$byClass[\"Specificity\"],\n    Precision = cm_obj$byClass[\"Pos Pred Value\"],\n    F1 = cm_obj$byClass[\"F1\"]\n  )\n}\n\n# Create the table\nxgb_metrics_table &lt;- rbind(\n  cbind(Model = \"Model 1 - Train\", extract_metrics(CM.models.binary_ADHD_1$Train$XGBOOST)),\n  cbind(Model = \"Model 1 - Test\",  extract_metrics(CM.models.binary_ADHD_1$Test$XGBOOST)),\n  cbind(Model = \"Model 2 - Train\", extract_metrics(CM.models.binary_ADHD_2$Train$XGBOOST)),\n  cbind(Model = \"Model 2 - Test\",  extract_metrics(CM.models.binary_ADHD_2$Test$XGBOOST)),\n  cbind(Model = \"Model 3 - Train\", extract_metrics(CM.models.binary_ADHD_3$Train$XGBOOST)),\n  cbind(Model = \"Model 3 - Test\",  extract_metrics(CM.models.binary_ADHD_3$Test$XGBOOST))\n)\n\n# View or export\nprint(xgb_metrics_table)\n\n                    Model  Accuracy Sensitivity Specificity Precision        F1\nAccuracy  Model 1 - Train 0.9130435   0.6969697   1.0000000 1.0000000 0.8214286\nAccuracy1  Model 1 - Test 0.7368421   0.7272727   0.7407407 0.5333333 0.6153846\nAccuracy2 Model 2 - Train 0.9130435   0.7272727   0.9878049 0.9600000 0.8275862\nAccuracy3  Model 2 - Test 0.7631579   0.7272727   0.7777778 0.5714286 0.6400000\nAccuracy4 Model 3 - Train 0.9652174   0.9090909   0.9878049 0.9677419 0.9375000\nAccuracy5  Model 3 - Test 0.7368421   0.8181818   0.7037037 0.5294118 0.6428571\n\n#RF seems the winner (I do not think that Alex agreed here). \n# Updated helper function to compute Mean_Balanced_Accuracy using multiClassSummary\ncalc_balacc &lt;- function(mod, truth, newdata) {\n  # Get predicted probabilities and predicted class labels\n  prob &lt;- predict(mod, newdata = newdata, type = \"prob\")\n  pred &lt;- predict(mod, newdata = newdata)\n  \n  # Build a data frame with observed values, predictions, and probabilities.\n  # The column names in 'prob' must match the levels in the response factor.\n  df &lt;- data.frame(obs = truth,\n                   pred = pred,\n                   prob)\n  \n  # multiClassSummary computes several metrics including Mean_Balanced_Accuracy.\n  # Note: Even in binary classification, it returns \"Mean_Balanced_Accuracy\".\n  metrics &lt;- multiClassSummary(df, lev = levels(truth), model = mod)\n  metrics[\"Balanced_Accuracy\"]\n}\n\n# Updated evaluation function that computes balanced accuracy on train and test sets\nevaluate_models_balacc &lt;- function(model_list, train_data, test_data, response_col) {\n  train_balacc &lt;- sapply(model_list, function(mod) \n    calc_balacc(mod, truth = train_data[[response_col]], newdata = train_data))\n  \n  test_balacc &lt;- sapply(model_list, function(mod) \n    calc_balacc(mod, truth = test_data[[response_col]], newdata = test_data))\n  \n  data.frame(\n    Model = names(model_list),\n    Train_BalAcc = train_balacc,\n    Test_BalAcc  = test_balacc,\n    Diff = train_balacc - test_balacc,\n    row.names = NULL\n  )\n}\n\n# Example usage for group 1 and group 2 binary models\n\nBI_results1 &lt;- evaluate_models_balacc(\n  model_list = models.binary_ADHD_1,\n  train_data = train_data_ADHD_Status,\n  test_data = test_data_ADHD_Status,\n  response_col = \"ADHD\"\n)\n\nBI_results2 &lt;- evaluate_models_balacc(\n  model_list = models.binary_ADHD_2,\n  train_data = train_data_ADHD_Status,\n  test_data = test_data_ADHD_Status,\n  response_col = \"ADHD\"\n)\n\nBI_results3 &lt;- evaluate_models_balacc(\n  model_list = models.binary_ADHD_3,\n  train_data = train_data_ADHD_Status,\n  test_data = test_data_ADHD_Status,\n  response_col = \"ADHD\"\n)\n\n# Combine the results from the two groups for comparison\nBI_results1$Set &lt;- \"No L2\"\nBI_results2$Set &lt;- \"With L2\"\nBI_results3$Set &lt;- \"BAARS\"\nBI_results_all &lt;- rbind(BI_results1, BI_results2, BI_results3)\n\n# Print the combined balanced accuracy results\nBI_results_all\n\n     Model Train_BalAcc Test_BalAcc        Diff     Set\n1    Logit    0.6241685   0.6632997 -0.03913115   No L2\n2    Lasso    0.5938655   0.6178451 -0.02397963   No L2\n3      LDA    0.6393200   0.6632997 -0.02397963   No L2\n4      QDA    0.7180340   0.6902357  0.02779831   No L2\n5       RF    0.9848485   0.6632997  0.32154882   No L2\n6  XGBOOST    0.8484848   0.7340067  0.11447811   No L2\n7    Logit    0.6210273   0.7542088 -0.13318141 With L2\n8    Lasso    0.5303030   0.5454545 -0.01515152 With L2\n9      LDA    0.6361789   0.7542088 -0.11802989 With L2\n10     QDA    0.7422395   0.6902357  0.05200378 With L2\n11      RF    1.0000000   0.5269360  0.47306397 With L2\n12 XGBOOST    0.8575388   0.7525253  0.10501355 With L2\n13   Logit    0.8179970   0.7340067  0.08399031   BAARS\n14   Lasso    0.7756837   0.7525253  0.02315841   BAARS\n15     LDA    0.7756837   0.7525253  0.02315841   BAARS\n16     QDA    0.8695492   0.7626263  0.10692289   BAARS\n17      RF    1.0000000   0.7255892  0.27441077   BAARS\n18 XGBOOST    0.9484479   0.7609428  0.18750513   BAARS\n\n\nStep 3: Computing SHAP Values for RF to understand what predictors are the most influential\n\n# Create a character vector with the names of the selected predictors\nselected_vars &lt;- c(\"L2\", \"SRT\", \"DM\", \"WM\", \"PHQ\", \"Sex\", \"Age\", \n                   \"SpokenLanguages\", \"Education\")\n\n# Subset the training data for SHAP analysis\nBI_X_train &lt;- ProjectData[, selected_vars]\n\n# For binary classification, define a prediction wrapper that returns probabilities for the positive class.\npredict_prob_BI &lt;- function(model, newdata) {\n  prob &lt;- predict(model, newdata = newdata, type = \"prob\")\n  prob[, 2]\n}\n\n# Compute SHAP values using fastshap for one of the QDR models\nset.seed(123)  # For reproducibility\nBI_shap_vals_RF &lt;- fastshap::explain(\n  object = models.binary_ADHD_2$RF, \n  X = BI_X_train,\n  pred_wrapper = predict_prob_BI,\n  nsim = 50\n)\n\n# Calculate absolute SHAP values for each predictor\nBI_abs_mean_RF &lt;- colMeans(abs(BI_shap_vals_RF))\n\n# Create a data frame for absolute SHAP values for plotting\ndf_BI_shap_abs &lt;- data.frame(\n  Variable = names(BI_abs_mean_RF),\n  Mean_SHAP = BI_abs_mean_RF\n)\n\n# Order variables by importance \ndf_BI_shap_abs &lt;- df_BI_shap_abs %&gt;%\n  arrange(desc(Mean_SHAP))\n\n# Create a bar plot of the absolute mean SHAP values\nShap_Means_BI &lt;- ggplot(df_BI_shap_abs, aes(x = reorder(Variable, Mean_SHAP), y = Mean_SHAP)) +\n  geom_bar(stat = \"identity\", fill = \"#F8766D\") +\n  labs(title = \"Absolute Mean SHAP Values for RF Binary Model\",\n       x = \"Variable\",\n       y = \"Absolute Mean SHAP Value\") +\n  coord_flip() +\n  theme_minimal()\n\nShap_Means_BI"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "portfolio",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  }
]